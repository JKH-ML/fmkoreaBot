import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import re
import requests
import json
import os

# ì„¤ì •
DB_FILE = "notified_ids.json"
WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK')
# ì¸ê¸°ìˆœ(pop) ì •ë ¬ì´ ìœ ì§€ëœ ê¸°ë³¸ ì£¼ì†Œ
BASE_URL = "https://www.fmkorea.com/index.php?mid=afreecatv&sort_index=pop&order_type=desc&page="

async def run_bot():
    # 1. ê¸°ì¡´ ì•Œë¦¼ ëª©ë¡ ë¡œë“œ
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, 'r', encoding='utf-8') as f:
                notified_ids = set(json.load(f))
        except:
            notified_ids = set()
    else:
        notified_ids = set()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        
        newly_notified = []

        try:
            # ì¸ê¸°ìˆœ í˜ì´ì§€ 1ë¶€í„° 5ê¹Œì§€ ìˆœíšŒ
            for page_num in range(1, 6):
                target_url = f"{BASE_URL}{page_num}"
                print(f"ğŸ” ì¸ê¸°ìˆœ {page_num}í˜ì´ì§€ ë¶„ì„ ì¤‘...")
                
                await page.goto(target_url, wait_until="load", timeout=60000)
                await page.wait_for_timeout(7000) # ìë°”ìŠ¤í¬ë¦½íŠ¸ ë¡œë”© ëŒ€ê¸°
                
                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')
                posts = soup.select("li.li")

                for post in posts:
                    try:
                        # ì¶”ì²œìˆ˜ ì¶”ì¶œ
                        vote_tag = post.select_one(".pc_voted_count .count")
                        if not vote_tag: continue
                        
                        votes = int(re.sub(r'[^0-9]', '', vote_tag.get_text()) or 0)
                        
                        # ê¸°ì¤€: 250ì¶” ì´ìƒ
                        if votes >= 250:
                            link_tag = post.select_one("h3.title a")
                            raw_href = link_tag['href']
                            
                            # ê³ ìœ  ID(document_srl) ì¶”ì¶œ
                            if 'document_srl=' in raw_href:
                                post_id = raw_href.split('document_srl=')[-1].split('&')[0]
                            else:
                                post_id = raw_href.strip('/')

                            # ì¤‘ë³µ ì•Œë¦¼ ì²´í¬
                            if post_id not in notified_ids:
                                title_tag = post.select_one(".ellipsis-target")
                                title = title_tag.get_text(strip=True) if title_tag else "ì œëª©ì—†ìŒ"
                                full_link = f"https://www.fmkorea.com{raw_href}" if raw_href.startswith('/') else raw_href
                                
                                if WEBHOOK_URL:
                                    msg = f"ğŸ”¥ **250ì¶” ëŒíŒŒ ì¸ê¸°ê¸€**\n**ì œëª©:** {title}\n**ì¶”ì²œ:** {votes}ê°œ\n**ë§í¬:** {full_link}"
                                    requests.post(WEBHOOK_URL, json={"content": msg})
                                    notified_ids.add(post_id)
                                    newly_notified.append(title)
                                    print(f"âœ… ì•Œë¦¼ ì „ì†¡: {title} ({votes}ì¶”)")
                    except Exception:
                        continue
                
                await asyncio.sleep(1.5) # í˜ì´ì§€ ê°„ ì•ˆì „ ëŒ€ê¸°

            # 2. ê²°ê³¼ ì €ì¥
            with open(DB_FILE, 'w', encoding='utf-8') as f:
                json.dump(list(notified_ids)[-1000:], f)
            print(f"âœ… ì‘ì—… ì™„ë£Œ. ìƒˆ ì•Œë¦¼: {len(newly_notified)}ê°œ")

        finally:
            await browser.close()

if __name__ == "__main__":
    asyncio.run(run_bot())